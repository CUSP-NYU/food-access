{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "honest-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "derived-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(df):\n",
    "    display(df.iloc[0:3, :])\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dramatic-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_dates(df):\n",
    "    df['date_range_start'] = pd.to_datetime(df['date_range_start'], utc=True)\n",
    "    df['date_range_start'] = df['date_range_start'].dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothen(df, columns=[], N=6):\n",
    "    \"\"\"Returns a copy of the given dataframe with a rolling-day average of the\n",
    "    given size applied to the given columns.\"\"\"\n",
    "    rolling_avg_df = df.copy().reset_index(drop=True)\n",
    "    # An N-day rolling average with N/2 days before and N/2 after requires N+1\n",
    "    # days to include the day of as well.\n",
    "    rolling_avg_df[columns] = (\n",
    "        rolling_avg_df[columns].rolling(N + 1, center=True).mean())\n",
    "    return rolling_avg_df\n",
    "\n",
    "def smoothen_within(df, columns=[], by=None, N=6):\n",
    "    \"\"\"Returns a copy of the given dataframe with a rolling-day average of the\n",
    "    given size applied to the given columns within each attribute class\n",
    "    determined by the given \"by\" attribute.\"\"\"\n",
    "    attr_classes = set(df[by])\n",
    "    rolling_dfs = []\n",
    "    for attr_class in attr_classes:\n",
    "        attr_class_df = df[df[by] == attr_class]\n",
    "        rolling_dfs.append(smoothen(attr_class_df, columns, N=N))\n",
    "    rolling_df = pd.concat(rolling_dfs)\n",
    "    rolling_df = rolling_df.sort_values(by=['date_range_start', by])\n",
    "    return rolling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placekey</th>\n",
       "      <th>date_range_start</th>\n",
       "      <th>cbg</th>\n",
       "      <th>visitor_count</th>\n",
       "      <th>estimated_visitor_count</th>\n",
       "      <th>pct_visitor_count</th>\n",
       "      <th>pct_estimated_visitor_count</th>\n",
       "      <th>cdi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>22t-222@627-s7m-rtv</td>\n",
       "      <td>2019-01-07 00:00:00-05:00</td>\n",
       "      <td>360050001000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>22t-222@627-s7m-rtv</td>\n",
       "      <td>2019-01-07 00:00:00-05:00</td>\n",
       "      <td>360470206001</td>\n",
       "      <td>4</td>\n",
       "      <td>9.790000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>2.772665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>22t-222@627-s7m-rtv</td>\n",
       "      <td>2019-01-07 00:00:00-05:00</td>\n",
       "      <td>360470435003</td>\n",
       "      <td>4</td>\n",
       "      <td>8.605042</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>2.437068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>22t-222@627-s7m-rtv</td>\n",
       "      <td>2019-01-07 00:00:00-05:00</td>\n",
       "      <td>360470437001</td>\n",
       "      <td>4</td>\n",
       "      <td>11.749526</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>3.327630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>22t-222@627-s7m-rtv</td>\n",
       "      <td>2019-01-07 00:00:00-05:00</td>\n",
       "      <td>360470573002</td>\n",
       "      <td>5</td>\n",
       "      <td>1.068101</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.302501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               placekey          date_range_start           cbg  \\\n",
       "95  22t-222@627-s7m-rtv 2019-01-07 00:00:00-05:00  360050001000   \n",
       "96  22t-222@627-s7m-rtv 2019-01-07 00:00:00-05:00  360470206001   \n",
       "97  22t-222@627-s7m-rtv 2019-01-07 00:00:00-05:00  360470435003   \n",
       "98  22t-222@627-s7m-rtv 2019-01-07 00:00:00-05:00  360470437001   \n",
       "99  22t-222@627-s7m-rtv 2019-01-07 00:00:00-05:00  360470573002   \n",
       "\n",
       "    visitor_count  estimated_visitor_count  pct_visitor_count  \\\n",
       "95              4                 0.000000           0.333333   \n",
       "96              4                 9.790000           0.021739   \n",
       "97              4                 8.605042           0.016129   \n",
       "98              4                11.749526           0.024390   \n",
       "99              5                 1.068101           0.005160   \n",
       "\n",
       "    pct_estimated_visitor_count       cdi  \n",
       "95                     0.000000  0.000000  \n",
       "96                     0.021739  2.772665  \n",
       "97                     0.016129  2.437068  \n",
       "98                     0.024390  3.327630  \n",
       "99                     0.005160  0.302501  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_df = pd.read_csv(f'./exports/home_weekly.csv')\n",
    "repair_dates(home_df)\n",
    "home_df = home_df[home_df['date_range_start'].dt.year.isin([2019, 2020])]\n",
    "home_df = home_df.rename(columns={'home_cbg': 'cbg'})\n",
    "home_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-thread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placekey</th>\n",
       "      <th>is_fast_food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226-222@627-s4n-pqf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225-225@627-s99-9xq</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225-225@627-vsw-7nq</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              placekey  is_fast_food\n",
       "0  226-222@627-s4n-pqf         False\n",
       "1  225-225@627-s99-9xq         False\n",
       "2  225-225@627-vsw-7nq         False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36467\n"
     ]
    }
   ],
   "source": [
    "poi_df = pd.read_csv(f'./exports/poi_health_recategorized.csv')\n",
    "poi_ffr_df = poi_df\n",
    "poi_ffr_df['is_fast_food'] = (poi_ffr_df['category'] == 'Fast-Food Restaurants')\n",
    "poi_ffr_df = poi_ffr_df[['placekey', 'is_fast_food']]\n",
    "peek(poi_ffr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df = home_df.merge(poi_ffr_df, on=['placekey'], how='inner')\n",
    "peek(home_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df['estimated_ffr_visitor_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df.loc[home_df['is_fast_food'],\n",
    "            'estimated_ffr_visitor_count'] = home_df['estimated_visitor_count']\n",
    "peek(home_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_df(metric_df, diff_columns=[], keep_columns=[]):\n",
    "    metric_week_df = metric_df\n",
    "    metric_week_df['year'] = metric_week_df['date_range_start'].dt.year\n",
    "    metric_week_df['week'] = metric_week_df['date_range_start'].dt.week\n",
    "\n",
    "    # Dates are missing from December 2020!\n",
    "\n",
    "    metric_2020_df = metric_week_df[metric_week_df['year'] == 2020]\n",
    "    metric_2020_df = metric_2020_df[metric_2020_df['week'] >= 2]\n",
    "    metric_2020_df = metric_2020_df[metric_2020_df['week'] <= 52].reset_index(\n",
    "        drop=True)\n",
    "    metric_2019_df = metric_week_df[metric_week_df['year'] == 2019]\n",
    "    metric_2019_df = metric_2019_df[metric_2019_df['week'] >= 2]\n",
    "    # Remove dates that can't be compared.\n",
    "    metric_2019_df = metric_2019_df[~metric_2019_df['week'].isin(set([50, 51]))]\n",
    "    metric_2019_df = metric_2019_df[metric_2019_df['week'] <= 52].reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    metric_diff_df = pd.DataFrame()\n",
    "    for keep_column in (keep_columns + ['week', 'date_range_start']):\n",
    "        metric_diff_df[keep_column] = metric_2020_df[keep_column]\n",
    "    metric_diff_df[diff_columns] = (metric_2020_df[diff_columns] -\n",
    "                                    metric_2019_df[diff_columns])\n",
    "    metric_diff_df = metric_diff_df.dropna()\n",
    "\n",
    "    peek(metric_diff_df.head())\n",
    "\n",
    "    return metric_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = home_df.groupby(by=['date_range_start']).agg({\n",
    "    'estimated_visitor_count': 'sum',\n",
    "    'estimated_ffr_visitor_count': 'sum',\n",
    "}).reset_index()\n",
    "trips_df['pct_ffr'] = trips_df['estimated_ffr_visitor_count'] / trips_df[\n",
    "    'estimated_visitor_count']\n",
    "peek(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_diff_df = create_diff_df(trips_df, diff_columns=['pct_ffr'])\n",
    "trips_diff_df = smoothen(trips_diff_df, columns=['pct_ffr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(trips_diff_df['date_range_start'],\n",
    "        trips_diff_df['pct_ffr'],\n",
    "        color='C0')\n",
    "ax.set_title('Diff in % of Trips to FFRs (52 Weeks)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg_df = pd.read_csv('./exports/proximity_clusters.csv')\n",
    "cbg_df = cbg_df[['cbg', 'cluster', 'population']]\n",
    "peek(cbg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = home_df.merge(cbg_df, how='inner', on=['cbg'])\n",
    "peek(merge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = merge_df.groupby(by=['date_range_start', 'cluster']).agg({\n",
    "    'estimated_visitor_count': 'sum',\n",
    "    'estimated_ffr_visitor_count': 'sum',\n",
    "}).reset_index()\n",
    "cluster_df = cluster_df.sort_values(by=['date_range_start', 'cluster'])\n",
    "cluster_df['pct_ffr'] = cluster_df['estimated_ffr_visitor_count'] / cluster_df[\n",
    "    'estimated_visitor_count']\n",
    "cluster_df = smoothen_within(cluster_df, columns=['pct_ffr'], by='cluster')\n",
    "peek(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "for key, group in cluster_df.groupby(by=['cluster']):\n",
    "    ax.plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax.set_title('% of Trips to FFRs')\n",
    "ax.axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "proximity_df = pd.read_csv('./exports/proximity_count_index_sampled.csv')\n",
    "peek(proximity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_index = np.median(proximity_df['category_0_proximity_index'])\n",
    "proximity_df['near_ffr'] = proximity_df['category_0_proximity_index'] > median_index\n",
    "median_index = np.median(proximity_df['category_1_proximity_index'])\n",
    "proximity_df['near_ssfs'] = proximity_df['category_1_proximity_index'] > median_index\n",
    "proximity_df['near_ffr_only'] = (~proximity_df['near_ssfs'] & proximity_df['near_ffr'])\n",
    "proximity_df['near_ssfs_only'] = (proximity_df['near_ssfs'] & ~proximity_df['near_ffr'])\n",
    "peek(proximity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_proximity_df = merge_df.merge(proximity_df, how='inner', on=['cbg'])\n",
    "peek(merge_proximity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_ffr_df = merge_proximity_df.groupby(\n",
    "    by=['date_range_start', 'near_ffr']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "near_ffr_df['pct_ffr'] = near_ffr_df[\n",
    "    'estimated_ffr_visitor_count'] / near_ffr_df['estimated_visitor_count']\n",
    "near_ffr_diff_df = create_diff_df(near_ffr_df,\n",
    "                                  diff_columns=['pct_ffr'],\n",
    "                                  keep_columns=['near_ffr'])\n",
    "near_ffr_df = smoothen_within(near_ffr_df, columns=['pct_ffr'], by='near_ffr')\n",
    "near_ffr_diff_df = smoothen_within(near_ffr_diff_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='near_ffr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_ffr_only_df = merge_proximity_df.groupby(\n",
    "    by=['date_range_start', 'near_ffr_only']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "near_ffr_only_df['pct_ffr'] = near_ffr_only_df[\n",
    "    'estimated_ffr_visitor_count'] / near_ffr_only_df['estimated_visitor_count']\n",
    "near_ffr_only_diff_df = create_diff_df(near_ffr_only_df,\n",
    "                                       diff_columns=['pct_ffr'],\n",
    "                                       keep_columns=['near_ffr_only'])\n",
    "near_ffr_only_df = smoothen_within(near_ffr_only_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='near_ffr_only')\n",
    "near_ffr_only_diff_df = smoothen_within(near_ffr_only_diff_df,\n",
    "                                        columns=['pct_ffr'],\n",
    "                                        by='near_ffr_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_ssfs_df = merge_proximity_df.groupby(\n",
    "    by=['date_range_start', 'near_ssfs']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "near_ssfs_df['pct_ffr'] = near_ssfs_df[\n",
    "    'estimated_ffr_visitor_count'] / near_ssfs_df['estimated_visitor_count']\n",
    "near_ssfs_diff_df = create_diff_df(near_ssfs_df,\n",
    "                                       diff_columns=['pct_ffr'],\n",
    "                                       keep_columns=['near_ssfs'])\n",
    "near_ssfs_df = smoothen_within(near_ssfs_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='near_ssfs')\n",
    "near_ssfs_diff_df = smoothen_within(near_ssfs_diff_df,\n",
    "                                        columns=['pct_ffr'],\n",
    "                                        by='near_ssfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_ssfs_only_df = merge_proximity_df.groupby(\n",
    "    by=['date_range_start', 'near_ssfs_only']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "near_ssfs_only_df['pct_ffr'] = near_ssfs_only_df[\n",
    "    'estimated_ffr_visitor_count'] / near_ssfs_only_df['estimated_visitor_count']\n",
    "near_ssfs_only_diff_df = create_diff_df(near_ssfs_only_df,\n",
    "                                       diff_columns=['pct_ffr'],\n",
    "                                       keep_columns=['near_ssfs_only'])\n",
    "near_ssfs_only_df = smoothen_within(near_ssfs_only_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='near_ssfs_only')\n",
    "near_ssfs_only_diff_df = smoothen_within(near_ssfs_only_diff_df,\n",
    "                                        columns=['pct_ffr'],\n",
    "                                        by='near_ssfs_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(20, 16))\n",
    "\n",
    "for key, group in near_ffr_df.groupby(by=['near_ffr']):\n",
    "    ax[0, 0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[0, 0].set_title('% of Trips to FFRs (Top 50% FFR Proximity)')\n",
    "\n",
    "for key, group in near_ffr_diff_df.groupby(by=['near_ffr']):\n",
    "    ax[0, 1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[0, 1].set_title('Diff % of Trips to FFRs (Top 50% FFR Proximity)')\n",
    "\n",
    "for key, group in near_ssfs_df.groupby(by=['near_ssfs']):\n",
    "    ax[1, 0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[1, 0].set_title('% of Trips to FFRs (Top 50% SSFS Proximity)')\n",
    "\n",
    "for key, group in near_ssfs_diff_df.groupby(by=['near_ssfs']):\n",
    "    ax[1, 1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[1, 1].set_title('Diff % of Trips to FFRs (Top 50% SSFS Proximity)')\n",
    "\n",
    "for key, group in near_ffr_only_df.groupby(by=['near_ffr_only']):\n",
    "    ax[2, 0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[2, 0].set_title('% of Trips to FFRs (Top 50% FFR Bottom 50% SSFS Proximity)')\n",
    "\n",
    "for key, group in near_ffr_only_diff_df.groupby(by=['near_ffr_only']):\n",
    "    ax[2, 1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[2, 1].set_title(\n",
    "    'Diff % of Trips to FFRs (Top 50% FFR Bottom 50% SSFS Proximity)')\n",
    "\n",
    "for key, group in near_ssfs_only_df.groupby(by=['near_ssfs_only']):\n",
    "    ax[3, 0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[3, 0].set_title('% of Trips to FFRs (Bottom 50% FFR Top 50% SSFS Proximity)')\n",
    "\n",
    "for key, group in near_ssfs_only_diff_df.groupby(by=['near_ssfs_only']):\n",
    "    ax[3, 1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[3, 1].set_title(\n",
    "    'Diff % of Trips to FFRs (Bottom 50% FFR Top 50% SSFS Proximity)')\n",
    "\n",
    "ax[0, 0].legend()\n",
    "ax[0, 1].legend()\n",
    "ax[1, 0].legend()\n",
    "ax[1, 1].legend()\n",
    "ax[2, 0].legend()\n",
    "ax[2, 0].legend()\n",
    "ax[3, 1].legend()\n",
    "ax[3, 1].legend()\n",
    "\n",
    "ax[0, 0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[0, 1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[1, 0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[1, 1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[2, 0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[2, 1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[3, 0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[3, 1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg_gdf = gpd.read_file('./data/nyc_cbgs.geojson')\n",
    "cbg_gdf = cbg_gdf.rename(columns={\n",
    "    'CensusBlockGroup': 'cbg',\n",
    "})\n",
    "cbg_gdf['cbg'] = cbg_gdf['cbg'].astype(int)\n",
    "cbg_gdf = cbg_gdf[['cbg', 'geometry']]\n",
    "\n",
    "cbg_gdf = cbg_gdf.merge(\n",
    "    proximity_df[['cbg', 'near_ffr', 'near_ssfs', 'near_ffr_only', 'near_ssfs_only']],\n",
    "    on=['cbg'],\n",
    "    how='inner')\n",
    "\n",
    "cbg_gdf['color_ffr'] = 'C' + cbg_gdf['near_ffr'].astype(int).astype(str)\n",
    "cbg_gdf['color_ssfs'] = 'C' + cbg_gdf['near_ssfs'].astype(int).astype(str)\n",
    "cbg_gdf['color_ffr_only'] = 'C' + cbg_gdf['near_ffr_only'].astype(int).astype(str)\n",
    "cbg_gdf['color_ssfs_only'] = 'C' + cbg_gdf['near_ssfs_only'].astype(int).astype(str)\n",
    "\n",
    "cbg_df = pd.read_csv('./data/cbg_attr_and_cluster_1021.csv')\n",
    "cbg_df = cbg_df.rename(columns={\n",
    "    'census_block_group': 'cbg',\n",
    "    'Median Household Income': 'income',\n",
    "    'Total Population': 'population',\n",
    "})\n",
    "cbg_df = cbg_df[['cbg', 'population', 'income']]\n",
    "\n",
    "cbg_gdf = cbg_gdf.merge(cbg_df, on=['cbg'], how='inner')\n",
    "cbg_gdf['area'] = cbg_gdf['geometry'].area * 1000 * 1000\n",
    "\n",
    "# XXX: Areas are already population-dependent.\n",
    "cbg_gdf['population_density'] = cbg_gdf['population'] / cbg_gdf['area']\n",
    "peek(cbg_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "cbg_gdf.plot(ax=ax[0], color=cbg_gdf['color_ffr'])\n",
    "cbg_gdf.plot(ax=ax[1], color=cbg_gdf['color_ssfs'])\n",
    "ax[0].set_title('Top 50% FFR Proximity')\n",
    "ax[1].set_title('Top 50% SSFS Proximity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "cbg_gdf.plot(ax=ax[0], color=cbg_gdf['color_ffr_only'])\n",
    "cbg_gdf.plot(ax=ax[1], color=cbg_gdf['color_ssfs_only'])\n",
    "ax[0].set_title('Top 50% FFR Bottom 50% SSFS Proximity')\n",
    "ax[1].set_title('Top 50% SSFS Bottom 50% FFR Proximity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_index = np.median(cbg_gdf['population_density'])\n",
    "cbg_gdf['is_dense'] = cbg_gdf['population_density'] > median_index\n",
    "cbg_gdf['color_is_dense'] = 'C' + cbg_gdf['is_dense'].astype(int).astype(str)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "cbg_gdf.plot(ax=ax, color=cbg_gdf['color_is_dense'])\n",
    "ax.set_title('Top 50% Population Density')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_density_df = merge_df.merge(cbg_gdf[['cbg', 'is_dense']], how='inner', on=['cbg'])\n",
    "dense_df = merge_density_df.groupby(\n",
    "    by=['date_range_start', 'is_dense']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "dense_df['pct_ffr'] = dense_df[\n",
    "    'estimated_ffr_visitor_count'] / dense_df['estimated_visitor_count']\n",
    "dense_diff_df = create_diff_df(dense_df,\n",
    "                                  diff_columns=['pct_ffr'],\n",
    "                                  keep_columns=['is_dense'])\n",
    "dense_df = smoothen_within(dense_df, columns=['pct_ffr'], by='is_dense')\n",
    "dense_diff_df = smoothen_within(dense_diff_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='is_dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "for key, group in dense_df.groupby(by=['is_dense']):\n",
    "    ax[0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[0].set_title('% of Trips to FFRs (Top 50% Population Density)')\n",
    "\n",
    "for key, group in dense_diff_df.groupby(by=['is_dense']):\n",
    "    ax[1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[1].set_title('Diff % of Trips to FFRs (Top 50% Population Density)')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Use NYC median income not median of CBG median income.\n",
    "#median_index = np.median(cbg_gdf['income'].dropna())\n",
    "median_index = 63998\n",
    "cbg_gdf['is_high_income'] = cbg_gdf['income'] > median_index\n",
    "cbg_gdf['color_is_high_income'] = 'C' + cbg_gdf['is_high_income'].astype(int).astype(str)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "cbg_gdf.plot(ax=ax, color=cbg_gdf['color_is_high_income'])\n",
    "ax.set_title('Top 50% Median Household Income')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_income_df = merge_df.merge(cbg_gdf[['cbg', 'is_high_income']], how='inner', on=['cbg'])\n",
    "income_df = merge_income_df.groupby(\n",
    "    by=['date_range_start', 'is_high_income']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "income_df['pct_ffr'] = income_df[\n",
    "    'estimated_ffr_visitor_count'] / income_df['estimated_visitor_count']\n",
    "income_diff_df = create_diff_df(income_df,\n",
    "                                  diff_columns=['pct_ffr'],\n",
    "                                  keep_columns=['is_high_income'])\n",
    "income_df = smoothen_within(income_df, columns=['pct_ffr'], by='is_high_income')\n",
    "income_diff_df = smoothen_within(income_diff_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='is_high_income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "for key, group in income_df.groupby(by=['is_high_income']):\n",
    "    ax[0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[0].set_title('% of Trips to FFRs (Top 50% Income)')\n",
    "\n",
    "for key, group in income_diff_df.groupby(by=['is_high_income']):\n",
    "    ax[1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[1].set_title('Diff % of Trips to FFRs (Top 50% Income)')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbg_gdf['is_low_density_high_income'] = cbg_gdf['is_dense'] & cbg_gdf['is_high_income']\n",
    "merge_income_density_df = merge_df.merge(cbg_gdf[['cbg', 'is_low_density_high_income']], how='inner', on=['cbg'])\n",
    "income_density_df = merge_income_density_df.groupby(\n",
    "    by=['date_range_start', 'is_low_density_high_income']).agg({\n",
    "        'estimated_visitor_count': 'sum',\n",
    "        'estimated_ffr_visitor_count': 'sum',\n",
    "    }).reset_index()\n",
    "income_density_df['pct_ffr'] = income_density_df[\n",
    "    'estimated_ffr_visitor_count'] / income_density_df['estimated_visitor_count']\n",
    "income_density_diff_df = create_diff_df(income_density_df,\n",
    "                                  diff_columns=['pct_ffr'],\n",
    "                                  keep_columns=['is_low_density_high_income'])\n",
    "income_density_df = smoothen_within(income_density_df, columns=['pct_ffr'], by='is_low_density_high_income')\n",
    "income_density_diff_df = smoothen_within(income_density_diff_df,\n",
    "                                   columns=['pct_ffr'],\n",
    "                                   by='is_low_density_high_income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "for key, group in income_density_df.groupby(by=['is_low_density_high_income']):\n",
    "    ax[0].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[0].set_title('% of Trips to FFRs (Bottom 50% Density Top 50% Income)')\n",
    "\n",
    "for key, group in income_density_diff_df.groupby(by=['is_low_density_high_income']):\n",
    "    ax[1].plot(group['date_range_start'], group['pct_ffr'], label=key)\n",
    "ax[1].set_title('Diff % of Trips to FFRs (Bottom 50% Density Top 50% Income)')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "ax[1].axvline(datetime.datetime(2020, 3, 20), linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Children\n",
    "# Driving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
